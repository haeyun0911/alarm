import cv2
import time
import numpy as np
from ultralytics import YOLO
import mediapipe as mp
from PIL import ImageFont, ImageDraw, Image

# 1. YOLO ëª¨ë¸ ë¡œë”©
try:
    model = YOLO("yolo11n.pt")  # yolov8n.pt ë˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸
except Exception as e:
    print(f"YOLO ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    exit()

# 2. Mediapipe Pose ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
mp_drawing = mp.solutions.drawing_utils

# 3. í•œê¸€ í°íŠ¸ ì„¤ì •
try:
    font_path = "C:/Windows/Fonts/malgun.ttf"
    font = ImageFont.truetype(font_path, 30)
except IOError:
    font = ImageFont.load_default()
    print("ë§‘ì€ ê³ ë”• í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")

# 4. ìƒíƒœ ê´€ë¦¬ ë³€ìˆ˜
alarm_on = False
lying_start_time = None
ALARM_THRESHOLD_SECONDS = 5

# 5. ìì„¸ íŒë³„ í•¨ìˆ˜
def check_posture(landmarks):
    """ëœë“œë§ˆí¬ë¥¼ ì´ìš©í•´ ìì„¸ê°€ 'ëˆ„ì›€'ì¸ì§€ 'ì„œìˆìŒ'ì¸ì§€ íŒë³„"""
    l_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]
    r_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]
    l_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP]
    r_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP]

    # 4ì  ëª¨ë‘ ê°€ì‹œì„± 0.6 ì´ˆê³¼ì¼ì‹œ íŒë³„
    if not all(p.visibility > 0.6 for p in [l_shoulder, r_shoulder, l_hip, r_hip]):
        return "unknown"

    # ì¢Œìš° ì–´ê¹¨, ì—‰ë©ì´ì˜ ì¤‘ì‹¬ì  ê³„ì‚°
    shoulder_center_x = (l_shoulder.x + r_shoulder.x) / 2
    shoulder_center_y = (l_shoulder.y + r_shoulder.y) / 2
    hip_center_x = (l_hip.x + r_hip.x) / 2
    hip_center_y = (l_hip.y + r_hip.y) / 2

    # ë‘ ì¤‘ì‹¬ì ì˜ ìˆ˜í‰ê±°ë¦¬ì™€ ìˆ˜ì§ê±°ë¦¬
    dx = abs(shoulder_center_x - hip_center_x)
    dy = abs(shoulder_center_y - hip_center_y)

    # ìˆ˜ì§ ê¸¸ì´ê°€ ìˆ˜í‰ ê¸¸ì´ì˜ 1.5ë°° ì´ìƒì´ë©´ 'ì„œìˆìŒ'ìœ¼ë¡œ íŒë³„
    is_upright = dy > dx * 1.5

    return "upright" if is_upright else "lying"

# 6. ë¹„ë””ì˜¤ ìº¡ì²˜ ì‹œì‘
video_path = "../../assets/6.mp4"
cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    print("ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# ğŸ¥ ê²°ê³¼ ì˜ìƒ ì €ì¥ ì¤€ë¹„ (ë¦¬ì‚¬ì´ì¦ˆëœ í¬ê¸°ë¡œ ì €ì¥)
original_height, original_width = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
new_width = int(original_width / 3)
new_height = int(original_height / 3)

fourcc = cv2.VideoWriter_fourcc(*'mp4v')
output_path = "output_result.mp4"
out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (new_width, new_height))

# 7. ë©”ì¸ ë£¨í”„
while True:
    ret, frame = cap.read()
    if not ret:
        print("ì˜ìƒ ëì— ë„ë‹¬í–ˆê±°ë‚˜ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break

    resized_frame = cv2.resize(frame, (new_width, new_height))
    results = model(resized_frame, verbose=False, classes=[0])  # ì‚¬ëŒë§Œ ê°ì§€
    person_boxes = results[0].boxes.xyxy.cpu().numpy()

    status_text = "ì‚¬ëŒ ì—†ìŒ"
    text_color = (0, 255, 0)

    # í•œëª… ì´ìƒì¼ì‹œ ê°€ì¥ í° ë°•ìŠ¤ë¥¼ ëŒ€í‘œ ì¸ë¬¼ë¡œ ì„ íƒ
    if len(person_boxes) > 0:
        main_person_box = max(person_boxes, key=lambda box: (box[2]-box[0])*(box[3]-box[1]))
        x1, y1, x2, y2 = map(int, main_person_box)

        rgb_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)
        pose_results = pose.process(rgb_frame)

        posture = "unknown"
        if pose_results.pose_landmarks:
            mp_drawing.draw_landmarks(
                resized_frame, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2),
                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2)
            )
            posture = check_posture(pose_results.pose_landmarks.landmark)

        if posture == "lying":
            if lying_start_time is None:
                lying_start_time = time.time()
            else:
                lying_duration = time.time() - lying_start_time
                remaining_time = ALARM_THRESHOLD_SECONDS - lying_duration
                if remaining_time > 0:
                    status_text = f"ëˆ„ì›ŒìˆëŠ” ì¤‘... {int(remaining_time)+1}ì´ˆ í›„ ì•ŒëŒ"
                    text_color = (0, 165, 255)
                else:
                    alarm_on = True
        elif posture == "upright":
            lying_start_time = None
            alarm_on = False
            status_text = "ì •ìƒ ìƒíƒœ"
            text_color = (0, 255, 0)
        else:
            status_text = "ìì„¸ ì¸ì‹ ë¶ˆê°€"
            text_color = (255, 255, 0)

        if alarm_on:
            status_text = f"ì•ŒëŒ! {ALARM_THRESHOLD_SECONDS}ì´ˆ ì´ìƒ ëˆ„ì›ŒìˆìŠµë‹ˆë‹¤!"
            text_color = (0, 0, 255)
    else:
        alarm_on = False
        lying_start_time = None

    # PILì„ ì´ìš©í•œ í•œê¸€ í…ìŠ¤íŠ¸ í‘œì‹œ
    frame_pil = Image.fromarray(cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(frame_pil)
    draw.text((20, 20), status_text, font=font, fill=(text_color[2], text_color[1], text_color[0]))
    resized_frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)

    # ê²°ê³¼ ì¶œë ¥ & ì €ì¥
    cv2.imshow("Lying Detection System", resized_frame)
    out.write(resized_frame)

    if cv2.waitKey(1) & 0xFF == 27:  # ESC ì¢…ë£Œ
        break

# 8. ë¦¬ì†ŒìŠ¤ í•´ì œ
cap.release()
out.release()
cv2.destroyAllWindows()
pose.close()
